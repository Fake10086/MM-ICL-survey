# Some interesting MM-ICL papers
1. **Visual In-Context Learning for Large Vision-Language Models (ACL' 24 findings)**
2. Towards Multimodal In-Context Learning for Vision & Language Models (ECCV' 24 workshop)
3. Unveiling and Mitigating Shortcuts in Multimodal In-Context Learning (ICLR' 25 workshop)
4. Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models (Arxiv)
5. Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information (EMNLP' 24 main)
6. Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning (AAAI' 25 student abstract)
7. **How to Configure Good In-Context Sequence for Visual Question Answering (CVPR '24)**
8. **Exploring Diverse In-Context Configurations for Image Captioning (Neurips' 23)**
9. Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations (ICLR' 25 workshop)
10. **Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features (Arxiv)**
11. **Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning (Neurips' 24)**
12. **Learnable In-Context Vector for Visual Question Answering (ICLR' 25)**
13. Boosting In-Context Learning of Large Multimodal Models with Symbol Demonstration Direct Preference Optimization (CVPR' 25)
14. **Identifying and Mitigating Position Bias of Multi-image Vision-Language Models (CVPR' 25)**
15. **What Factors Affect Multi-Modal In-Context Learning? An In-Depth Exploration (Neurips' 24)**
16. Principled Analysis of Demonstrations in Multimodal In-Context Learning (NAACL' 25 main)
17. **Lever LM: Configuring In-Context Sequence to Lever Large Vision Language Models (Neurips' 24)**
18. **Mimic In-Context Learning for Multimodal Tasks (CVPR' 25)**
19. **VL-ICL Bench: The Devil in the Details of Multimodal In-Context Learning (ICLR' 25)**
20. CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention (Arxiv)
21. Can Multimodal Large Language Models Truly Perform Multimodal In-Context Learning? (WACV' 24)
22. What Makes Multimodal In-Context Learning Work? (CVPR'24 workshop)
23. MÂ²IV: Towards Efficient and Fine-grained Multimodal InContext Learning in Large Vision-Language Models (Arxiv)
24. **AIM: Let Any Multimodal Large Language Models Embrace Effcient In-Context Learning (AAAI' 25)**
25. **True Multimodal In-Context Learning Needs Attention to the Visual Context (COLM' 25)**


